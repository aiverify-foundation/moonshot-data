import os

import anthropic
from anthropic.types import Message
from moonshot.src.connectors.connector import Connector, perform_retry
from moonshot.src.connectors.connector_response import ConnectorResponse
from moonshot.src.connectors_endpoints.connector_endpoint_arguments import (
    ConnectorEndpointArguments,
)


class AnthropicConnector(Connector):
    def __init__(self, ep_arguments: ConnectorEndpointArguments):
        # Initialize super class
        super().__init__(ep_arguments)

        # Initialize the AsyncAnthropic client with the API key and base URL. The API key is selected from the token
        # attribute if available; otherwise, it defaults to the ANTHROPIC_API_KEY environment variable.
        api_key = self.token or os.getenv("ANTHROPIC_API_KEY") or ""
        self._client = anthropic.AsyncAnthropic(api_key=api_key)

    @Connector.rate_limited
    @perform_retry
    async def get_response(self, prompt: str) -> ConnectorResponse:
        """
        Asynchronously sends a prompt to the Anthropic API and returns the generated response.

        This method constructs a request with the given prompt, optionally prepended and appended with
        predefined strings, and sends it to the Anthropic API. If a system prompt is set, it is included in the
        request. The method then awaits the response from the API, processes it, and returns the resulting message
        content wrapped in a ConnectorResponse object.

        Args:
            prompt (str): The input prompt to send to the Anthropic API.

        Returns:
            ConnectorResponse: An object containing the text response generated by the Anthropic model.
        """
        connector_prompt = f"{self.pre_prompt}{prompt}{self.post_prompt}"
        
        # Build messages list
        messages = [{"role": "user", "content": connector_prompt}]
        
        # Merge self.optional_params with additional parameters
        new_params = {
            **self.optional_params,
            "model": self.model,
            "messages": messages,
        }
        
        # Add system prompt if available
        if self.system_prompt:
            new_params["system"] = self.system_prompt
        
        # Validate that max_tokens is provided and is greater than 0
        # This assertion is to make the requirements from anthropic API clear to the user
        # The anthropic API will raise an error if max_tokens is not provided or is less than 0
        if "max_tokens" not in new_params or new_params.get("max_tokens", 0) <= 0:
            raise ValueError("max_tokens is required and must be greater than 0")
        
        response: Message = await self._client.messages.create(**new_params)
        return ConnectorResponse(response=await self._process_response(response))

    async def _process_response(self, response: Message) -> str:
        """
        Process an HTTP response and extract relevant information as a string.

        This function takes an HTTP response object as input and processes it to extract
        relevant information as a string. The extracted information may include data
        from the response body, headers, or other attributes.

        Args:
            response (Message): An Anthropic Message response object containing the response data.

        Returns:
            str: A string representing the relevant information extracted from the response.
        """
        # Extract text from all text content blocks in the response
        # Anthropic can return multiple content blocks (text, tool_use, etc.)
        # We filter for text blocks and join them together
        if not response.content:
            return ""
        
        text_blocks = []
        for block in response.content:
            # Check if this is a text block and extract its text
            if hasattr(block, "type") and block.type == "text" and hasattr(block, "text"):
                text_blocks.append(block.text)
        
        return "\n\n".join(text_blocks) if text_blocks else ""
