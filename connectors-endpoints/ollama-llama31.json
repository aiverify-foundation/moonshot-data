{
  "name": "Ollama Llama3.1",
  "connector_type": "openai-connector",
  "uri": "http://localhost:11434/v1/",
  "token": "ollama",
  "max_calls_per_second": 1,
  "max_concurrency": 1,
  "model": "llama3.1",
  "params": {
      "timeout": 300,
      "max_attempts": 3,
      "temperature": 0.5
  }
}